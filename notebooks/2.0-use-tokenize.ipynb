{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27b261f8-4424-4ef4-8ddb-445aba3b7947",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "from tokenize import tokenize, COMMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "274bb5d5-b5bf-4422-8e2f-c7807d6132f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/pyuser/workspace/code_sample/python/module1.py'),\n",
       " PosixPath('/home/pyuser/workspace/code_sample/python/module2.py'),\n",
       " PosixPath('/home/pyuser/workspace/code_sample/python/submodule/submodule1.py')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CODE_SAMPLE = Path(\".\").resolve().parent/\"code_sample\"/\"python\"\n",
    "code_samples = list(filter(lambda x: not x.match(\"*/.ipynb_checkpoints/*\"), CODE_SAMPLE.glob(\"**/*.py\")))\n",
    "code_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c2837d-787a-4084-afb8-4746f212ff6b",
   "metadata": {},
   "source": [
    "## Test with sample code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddca014e-93ba-4700-ab72-303648f277a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TokenInfo(type=63 (ENCODING), string='utf-8', start=(0, 0), end=(0, 0), line='')\n",
      "TokenInfo(type=62 (NL), string='\\n', start=(1, 0), end=(1, 1), line='\\n')\n",
      "TokenInfo(type=1 (NAME), string='import', start=(2, 0), end=(2, 6), line='import foobar\\n')\n",
      "TokenInfo(type=1 (NAME), string='foobar', start=(2, 7), end=(2, 13), line='import foobar\\n')\n",
      "TokenInfo(type=4 (NEWLINE), string='\\n', start=(2, 13), end=(2, 14), line='import foobar\\n')\n",
      "TokenInfo(type=1 (NAME), string='from', start=(3, 0), end=(3, 4), line='from foo import bar\\n')\n",
      "TokenInfo(type=1 (NAME), string='foo', start=(3, 5), end=(3, 8), line='from foo import bar\\n')\n",
      "TokenInfo(type=1 (NAME), string='import', start=(3, 9), end=(3, 15), line='from foo import bar\\n')\n",
      "TokenInfo(type=1 (NAME), string='bar', start=(3, 16), end=(3, 19), line='from foo import bar\\n')\n",
      "TokenInfo(type=4 (NEWLINE), string='\\n', start=(3, 19), end=(3, 20), line='from foo import bar\\n')\n",
      "TokenInfo(type=62 (NL), string='\\n', start=(4, 0), end=(4, 1), line='\\n')\n",
      "TokenInfo(type=61 (COMMENT), string='# this comentary', start=(5, 0), end=(5, 16), line='# this comentary\\n')\n",
      "TokenInfo(type=62 (NL), string='\\n', start=(5, 16), end=(5, 17), line='# this comentary\\n')\n",
      "TokenInfo(type=62 (NL), string='\\n', start=(6, 0), end=(6, 1), line='\\n')\n",
      "TokenInfo(type=1 (NAME), string='def', start=(7, 0), end=(7, 3), line='def func():\\n')\n",
      "TokenInfo(type=1 (NAME), string='func', start=(7, 4), end=(7, 8), line='def func():\\n')\n",
      "TokenInfo(type=54 (OP), string='(', start=(7, 8), end=(7, 9), line='def func():\\n')\n",
      "TokenInfo(type=54 (OP), string=')', start=(7, 9), end=(7, 10), line='def func():\\n')\n",
      "TokenInfo(type=54 (OP), string=':', start=(7, 10), end=(7, 11), line='def func():\\n')\n",
      "TokenInfo(type=4 (NEWLINE), string='\\n', start=(7, 11), end=(7, 12), line='def func():\\n')\n",
      "TokenInfo(type=5 (INDENT), string='    ', start=(8, 0), end=(8, 4), line='    return None\\n')\n",
      "TokenInfo(type=1 (NAME), string='return', start=(8, 4), end=(8, 10), line='    return None\\n')\n",
      "TokenInfo(type=1 (NAME), string='None', start=(8, 11), end=(8, 15), line='    return None\\n')\n",
      "TokenInfo(type=4 (NEWLINE), string='\\n', start=(8, 15), end=(8, 16), line='    return None\\n')\n",
      "TokenInfo(type=62 (NL), string='\\n', start=(9, 0), end=(9, 1), line='\\n')\n",
      "TokenInfo(type=6 (DEDENT), string='', start=(10, 0), end=(10, 0), line='')\n",
      "TokenInfo(type=0 (ENDMARKER), string='', start=(10, 0), end=(10, 0), line='')\n"
     ]
    }
   ],
   "source": [
    "code = \"\"\"\n",
    "import foobar\n",
    "from foo import bar\n",
    "\n",
    "# this comentary\n",
    "\n",
    "def func():\n",
    "    return None\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "for token in tokenize(BytesIO(code.encode('utf-8')).readline):\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8249344-a893-4c55-9b6b-c6587e651045",
   "metadata": {},
   "source": [
    "TokenInfo(type=63 (ENCODING), string='utf-8', start=(0, 0), end=(0, 0), line='')\n",
    "- `type=63 (ENCODING)` token type\n",
    "- `string='utf-8'` token string\n",
    "- `start=(0, 0)` (srow, scol) row and column start of token\n",
    "- `end=(0, 0)` row and column end of token\n",
    "- `line=''` line string on which the token was found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96f8d869-2542-4b26-b786-d5718cbc1726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TokenInfo(type=61 (COMMENT), string='# this comentary', start=(5, 0), end=(5, 16), line='# this comentary\\n')\n"
     ]
    }
   ],
   "source": [
    "for token in tokenize(BytesIO(code.encode('utf-8')).readline):\n",
    "    if token.type == COMMENT:\n",
    "        print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1245d6-98ac-466d-89ac-ade1e1246271",
   "metadata": {},
   "source": [
    "# Test with real code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cd71f66-ce30-4505-b3d2-58f9f19f37f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = '|'.join(['BUG', 'FIXME', 'NOTE', 'TODO'])\n",
    "regex = re.compile(f'(?:(?:# )({tags})(?::))')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c65155a1-a75a-4dba-a609-bc04250ad148",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 \t # NOTE: 'note' out of functions, module1, line 5, no closing brackets\n",
      "7 \t # NOTE: 'note' multirow, out of functions, module1, line 7, no closing brackets\n",
      "8 \t # 'note' multirow, out of functions, module1, line 8, no closing brackets\n",
      "10 \t # TODO: 'todo' out of functions, module1, line 10, with closing brackets <>\n",
      "14 \t # BUG: 'bug' in class, module1, line 14, brackets date 2022-01-01, multirow\n",
      "15 \t # 'bug' in class, module1, line 14, brackets date 2022-01-01, multirow <d:2022-01-01>\n",
      "26 \t # TODO: 'todo' in method, module1, line 26, no closing brackets\n",
      "35 \t # normal coment, do not include\n",
      "36 \t # FIXME: 'fixme' in function, module1, line 36, no brackets\n",
      "47 \t # TODO: 'todo' in function, module1, line 47, brackets p2, multiline\n",
      "48 \t # 'todo' in function, module1, line 47, brackets p2, multiline <p:2>\n",
      "50 \t # normal coment, do not include\n",
      "60 \t # FIXME: 'fixme' in function 'main', module1, line 60, with brackets p1 <p:1>\n",
      "61 \t # normal coment, do not include\n"
     ]
    }
   ],
   "source": [
    "with code_samples[0].open(mode='rb') as f:\n",
    "    tokens = tokenize(f.readline)\n",
    "    for token in tokens:\n",
    "        if token.type == COMMENT: # and regex.match(token.string):\n",
    "            print(token.start[0], \"\\t\", token.string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
